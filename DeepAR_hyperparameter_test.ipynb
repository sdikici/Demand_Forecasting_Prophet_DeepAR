{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPkpRYnpUPHMui6vxA42/p0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdikici/Demand_Forecasting_Prophet_DeepAR/blob/main/DeepAR_hyperparameter_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXQpX6sfq0ow"
      },
      "outputs": [],
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sercandikici/merged-dataset-electricty-weather-for-modelling\n",
        "! unzip merged-dataset-electricty-weather-for-modelling.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NRKt5FdXrAdP",
        "outputId": "b2246de3-aff8-4274-fe9d-24fea66d0e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/sercandikici/merged-dataset-electricty-weather-for-modelling\n",
            "License(s): unknown\n",
            "Downloading merged-dataset-electricty-weather-for-modelling.zip to /content\n",
            "100% 104k/104k [00:00<00:00, 361kB/s]\n",
            "100% 104k/104k [00:00<00:00, 361kB/s]\n",
            "Archive:  merged-dataset-electricty-weather-for-modelling.zip\n",
            "  inflating: merged_data.csv         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gluonts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5goxZcTrCUF",
        "outputId": "07a4c3f2-1970-4fbb-bbcb-b339ed8eaa55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gluonts\n",
            "  Downloading gluonts-0.14.4-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy~=1.16 in /usr/local/lib/python3.10/dist-packages (from gluonts) (1.25.2)\n",
            "Requirement already satisfied: pandas<2.2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gluonts) (2.0.3)\n",
            "Requirement already satisfied: pydantic<3,>=1.7 in /usr/local/lib/python3.10/dist-packages (from gluonts) (2.7.1)\n",
            "Requirement already satisfied: tqdm~=4.23 in /usr/local/lib/python3.10/dist-packages (from gluonts) (4.66.4)\n",
            "Requirement already satisfied: toolz~=0.10 in /usr/local/lib/python3.10/dist-packages (from gluonts) (0.12.1)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gluonts) (4.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0->gluonts) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0->gluonts) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.0,>=1.0->gluonts) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.7->gluonts) (2.18.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.0,>=1.0->gluonts) (1.16.0)\n",
            "Installing collected packages: gluonts\n",
            "Successfully installed gluonts-0.14.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mxnet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGEDCeR9rDrr",
        "outputId": "35841946-e888-46be-b24c-40922a724fe7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.1-py3-none-manylinux2014_x86_64.whl (49.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.31.0)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2024.2.2)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.3\n",
            "    Uninstalling graphviz-0.20.3:\n",
            "      Successfully uninstalled graphviz-0.20.3\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mxnet --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpInXpV8rI1G",
        "outputId": "c501580d-7ce9-4cbf-dbc8-18b8c94165af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.10/dist-packages (1.9.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.10/dist-packages (from mxnet) (2.31.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.20.0->mxnet) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.bool = np.bool_"
      ],
      "metadata": {
        "id": "slxrUl7DrKXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import mxnet as mx\n",
        "from mxnet import gluon\n",
        "import json\n",
        "from gluonts.dataset.common import ListDataset\n",
        "from gluonts.evaluation import Evaluator\n",
        "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
        "from gluonts.mx import DeepAREstimator\n",
        "from gluonts.mx.trainer import Trainer\n",
        "import itertools"
      ],
      "metadata": {
        "id": "TV_WxmEJrRcS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11a82120-297f-4f5d-8d06-f56136a22966"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gluonts/json.py:101: UserWarning: Using `json`-module for json-handling. Consider installing one of `orjson`, `ujson` to speed up serialization and deserialization.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Set the random seed for both MXNet (mx) and NumPy (np) libraries to ensure reproducibility of results.\n",
        "'''\n",
        "\n",
        "mx.random.seed(7)\n",
        "np.random.seed(7)"
      ],
      "metadata": {
        "id": "cpmM4qLVmzmJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Read the CSV file named \"merged_data.csv\" into a DataFrame named df_merged using the pd.read_csv function from the pandas library.\n",
        "Ensure that the 'settlement_date' column is interpreted as datetime by converting it using the pd.to_datetime function.\n",
        "'''\n",
        "df_merged = pd.read_csv(\"merged_data.csv\")\n",
        "df_merged['settlement_date'] = pd.to_datetime(df_merged['settlement_date'])"
      ],
      "metadata": {
        "id": "NjXFndsfrpjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Set the index of the DataFrame df_merged to the 'settlement_date' column and store the result in a new DataFrame named df_model_3.\n",
        "\n",
        "Define the split_from variable to determine the point of split between training and testing data. In this case, split_from is set to 90 days multiplied by 12, assuming hourly data.\n",
        "\n",
        "Split the df_model_3 DataFrame into training and testing sets:\n",
        "- train_data contains all data points from df_model_3 except for the last entries defined by split_from, representing the last 90 days' worth of data based on the assumption of hourly recordings.\n",
        "- test_data consists of the last 90 days' worth of data from df_model_3, serving as the dataset for evaluating the model's performance on unseen data.\n",
        "'''\n",
        "\n",
        "df_model_3 = df_merged.set_index(\"settlement_date\")\n",
        "\n",
        "split_from = 90*12 #train test split is from 90days\n",
        "train_data = df_model_3[:-split_from]\n",
        "test_data = df_model_3[-split_from:]"
      ],
      "metadata": {
        "id": "PYFfJgllrrhl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Define the frequency of the time series data as \"2H\" (2 hours).\n",
        "Specify the number of days to predict, and calculate the prediction_length by multiplying days_to_predict by 12.\n",
        "Set the context_length to twice the prediction_length, assuming a context_length of 2 times the prediction_length. This provides a longer context window for the model to learn patterns and make predictions.\n",
        "'''\n",
        "freq = \"2H\"\n",
        "days_to_predict=7\n",
        "prediction_length = days_to_predict*12 #predicting 7 days\n",
        "context_length = prediction_length *2"
      ],
      "metadata": {
        "id": "IrILy5Ggrxks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Define a parameter grid containing different combinations of hyperparameters for the DeepAR model, including epochs, num_batches_per_epoch, num_cells, num_layers, and dropout_rate.\n",
        "\n",
        "Generate all possible combinations of parameters using itertools.product and store them in all_params.\n",
        "\n",
        "Iterate over each parameter combination in all_params:\n",
        "    - Define a DeepAR estimator with the current set of parameters.\n",
        "    - Create training and testing datasets using ListDataset.\n",
        "    - Train the model on the training dataset.\n",
        "    - Generate forecasts on the testing dataset.\n",
        "    - Evaluate the forecasts using the Evaluator and calculate the MAPE.\n",
        "    - Append the MAPE to the list mapes.\n",
        "\n",
        "Combine the parameters and corresponding MAPEs into a DataFrame named tuning_results.\n",
        "\n",
        "Print the tuning_results DataFrame to display the results of hyperparameter tuning.\n",
        "'''\n",
        "\n",
        "param_grid = {\n",
        "    'epochs': [8, 12],\n",
        "    'num_batches_per_epoch': [100, 150],\n",
        "    'num_cells': [40, 64],\n",
        "    'num_layers': [2, 4],\n",
        "    'dropout_rate':[0.1, 0.01]\n",
        "}\n",
        "\n",
        "# Generate all combinations of parameters\n",
        "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
        "mapes = []  # Store the MAPEs for each parameter combination here\n",
        "\n",
        "# Use cross validation to evaluate all parameters\n",
        "for params in all_params:\n",
        "    # Define DeepAR estimator with given parameters\n",
        "    estimator = DeepAREstimator(\n",
        "        freq=freq,\n",
        "        context_length=context_length,\n",
        "        prediction_length=prediction_length,\n",
        "        cardinality = [1,1],\n",
        "        dropout_rate = params['dropout_rate'],\n",
        "        use_feat_dynamic_real =True, # weather temp\n",
        "        num_layers=params['num_layers'],\n",
        "        num_cells=params['num_cells'],\n",
        "        trainer=Trainer(\n",
        "            epochs=params['epochs'],\n",
        "            num_batches_per_epoch=params['num_batches_per_epoch']\n",
        "        )\n",
        "    )\n",
        "\n",
        "    train_ds = ListDataset(\n",
        "    [{\"start\":train_data.index[0],\n",
        "      \"target\":train_data.tsd,\n",
        "      \"feat_dynamic_real\": [train_data.temp],\n",
        "      \"feat_dynamic_cat\": [train_data.is_holiday],\n",
        "      }],\n",
        "    freq=freq\n",
        ")\n",
        "\n",
        "    test_ds = ListDataset(\n",
        "        [{\"start\":test_data.index[0],\n",
        "          \"target\":test_data.tsd,\n",
        "          \"feat_dynamic_real\": [test_data.temp],\n",
        "          \"feat_dynamic_cat\": [test_data.is_holiday],\n",
        "          }],\n",
        "        freq=freq\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    m = estimator.train(training_data=train_ds)\n",
        "    # Generate forecasts\n",
        "    forecast_it, ts_it = make_evaluation_predictions(\n",
        "        dataset=test_ds,\n",
        "        predictor=m,\n",
        "        num_samples=100\n",
        "    )\n",
        "    forecasts = list(forecast_it)\n",
        "    tss = list(ts_it)\n",
        "\n",
        "    # Get MAPE for the forecasts\n",
        "    evaluator = Evaluator()\n",
        "    agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts))\n",
        "    mape = agg_metrics[\"MAPE\"]\n",
        "    mapes.append(mape)\n",
        "\n",
        "# Combine parameters and corresponding MAPEs into a DataFrame\n",
        "tuning_results = pd.DataFrame(all_params)\n",
        "tuning_results['mape'] = mapes\n",
        "print(tuning_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUnWCjuvrPgH",
        "outputId": "cd917001-03ef-4ad4-81d3-d43db494cbee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 100/100 [00:38<00:00,  2.59it/s, epoch=1/8, avg_epoch_loss=9.61]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.77it/s, epoch=2/8, avg_epoch_loss=8.83]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.75it/s, epoch=3/8, avg_epoch_loss=8.67]\n",
            "100%|██████████| 100/100 [00:35<00:00,  2.79it/s, epoch=4/8, avg_epoch_loss=8.56]\n",
            "100%|██████████| 100/100 [00:35<00:00,  2.80it/s, epoch=5/8, avg_epoch_loss=8.49]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.78it/s, epoch=6/8, avg_epoch_loss=8.4]\n",
            "100%|██████████| 100/100 [00:35<00:00,  2.82it/s, epoch=7/8, avg_epoch_loss=8.35]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.72it/s, epoch=8/8, avg_epoch_loss=8.29]\n",
            "Running evaluation: 1it [00:00, 10.41it/s]\n",
            "100%|██████████| 100/100 [00:37<00:00,  2.64it/s, epoch=1/8, avg_epoch_loss=9.64]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.77it/s, epoch=2/8, avg_epoch_loss=8.94]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.76it/s, epoch=3/8, avg_epoch_loss=8.77]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.72it/s, epoch=4/8, avg_epoch_loss=8.68]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.76it/s, epoch=5/8, avg_epoch_loss=8.57]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.78it/s, epoch=6/8, avg_epoch_loss=8.52]\n",
            "100%|██████████| 100/100 [00:37<00:00,  2.68it/s, epoch=7/8, avg_epoch_loss=8.46]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.75it/s, epoch=8/8, avg_epoch_loss=8.41]\n",
            "Running evaluation: 1it [00:00, 10.55it/s]\n",
            "100%|██████████| 100/100 [01:06<00:00,  1.50it/s, epoch=1/8, avg_epoch_loss=9.53]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.59it/s, epoch=2/8, avg_epoch_loss=8.89]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.61it/s, epoch=3/8, avg_epoch_loss=8.71]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.60it/s, epoch=4/8, avg_epoch_loss=8.63]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.61it/s, epoch=5/8, avg_epoch_loss=8.53]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.63it/s, epoch=6/8, avg_epoch_loss=8.5]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.63it/s, epoch=7/8, avg_epoch_loss=8.49]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.63it/s, epoch=8/8, avg_epoch_loss=8.38]\n",
            "Running evaluation: 1it [00:00,  9.00it/s]\n",
            "100%|██████████| 100/100 [01:05<00:00,  1.53it/s, epoch=1/8, avg_epoch_loss=9.56]\n",
            "100%|██████████| 100/100 [01:04<00:00,  1.55it/s, epoch=2/8, avg_epoch_loss=8.9]\n",
            "100%|██████████| 100/100 [01:04<00:00,  1.55it/s, epoch=3/8, avg_epoch_loss=8.72]\n",
            "100%|██████████| 100/100 [01:04<00:00,  1.56it/s, epoch=4/8, avg_epoch_loss=8.63]\n",
            "100%|██████████| 100/100 [01:04<00:00,  1.56it/s, epoch=5/8, avg_epoch_loss=8.52]\n",
            "100%|██████████| 100/100 [01:03<00:00,  1.57it/s, epoch=6/8, avg_epoch_loss=8.42]\n",
            "100%|██████████| 100/100 [01:04<00:00,  1.55it/s, epoch=7/8, avg_epoch_loss=8.37]\n",
            "100%|██████████| 100/100 [01:03<00:00,  1.57it/s, epoch=8/8, avg_epoch_loss=8.27]\n",
            "Running evaluation: 1it [00:00,  7.74it/s]\n",
            "100%|██████████| 100/100 [00:44<00:00,  2.25it/s, epoch=1/8, avg_epoch_loss=9.56]\n",
            "100%|██████████| 100/100 [00:43<00:00,  2.31it/s, epoch=2/8, avg_epoch_loss=8.8]\n",
            "100%|██████████| 100/100 [00:43<00:00,  2.30it/s, epoch=3/8, avg_epoch_loss=8.62]\n",
            "100%|██████████| 100/100 [00:43<00:00,  2.32it/s, epoch=4/8, avg_epoch_loss=8.49]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.33it/s, epoch=5/8, avg_epoch_loss=8.4]\n",
            "100%|██████████| 100/100 [00:43<00:00,  2.30it/s, epoch=6/8, avg_epoch_loss=8.33]\n",
            "100%|██████████| 100/100 [00:43<00:00,  2.30it/s, epoch=7/8, avg_epoch_loss=8.26]\n",
            "100%|██████████| 100/100 [00:43<00:00,  2.33it/s, epoch=8/8, avg_epoch_loss=8.21]\n",
            "Running evaluation: 1it [00:00,  7.74it/s]\n",
            "100%|██████████| 100/100 [00:43<00:00,  2.28it/s, epoch=1/8, avg_epoch_loss=9.6]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.40it/s, epoch=2/8, avg_epoch_loss=8.85]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.42it/s, epoch=3/8, avg_epoch_loss=8.67]\n",
            "100%|██████████| 100/100 [00:40<00:00,  2.44it/s, epoch=4/8, avg_epoch_loss=8.53]\n",
            "100%|██████████| 100/100 [00:40<00:00,  2.44it/s, epoch=5/8, avg_epoch_loss=8.43]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.37it/s, epoch=6/8, avg_epoch_loss=8.36]\n",
            "100%|██████████| 100/100 [00:43<00:00,  2.32it/s, epoch=7/8, avg_epoch_loss=8.31]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.35it/s, epoch=8/8, avg_epoch_loss=8.28]\n",
            "Running evaluation: 1it [00:00,  7.71it/s]\n",
            "100%|██████████| 100/100 [01:17<00:00,  1.29it/s, epoch=1/8, avg_epoch_loss=9.52]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.36it/s, epoch=2/8, avg_epoch_loss=8.87]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.36it/s, epoch=3/8, avg_epoch_loss=8.73]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.36it/s, epoch=4/8, avg_epoch_loss=8.63]\n",
            "100%|██████████| 100/100 [01:14<00:00,  1.33it/s, epoch=5/8, avg_epoch_loss=8.56]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.35it/s, epoch=6/8, avg_epoch_loss=8.45]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=7/8, avg_epoch_loss=8.49]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.38it/s, epoch=8/8, avg_epoch_loss=8.32]\n",
            "Running evaluation: 1it [00:00,  6.80it/s]\n",
            "100%|██████████| 100/100 [01:16<00:00,  1.31it/s, epoch=1/8, avg_epoch_loss=9.83]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.36it/s, epoch=2/8, avg_epoch_loss=8.93]\n",
            "100%|██████████| 100/100 [01:14<00:00,  1.35it/s, epoch=3/8, avg_epoch_loss=8.8]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.36it/s, epoch=4/8, avg_epoch_loss=8.71]\n",
            "100%|██████████| 100/100 [01:14<00:00,  1.34it/s, epoch=5/8, avg_epoch_loss=8.6]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.36it/s, epoch=6/8, avg_epoch_loss=8.51]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=7/8, avg_epoch_loss=8.49]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.38it/s, epoch=8/8, avg_epoch_loss=8.4]\n",
            "Running evaluation: 1it [00:00,  6.70it/s]\n",
            "100%|██████████| 150/150 [00:58<00:00,  2.57it/s, epoch=1/8, avg_epoch_loss=9.42]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.67it/s, epoch=2/8, avg_epoch_loss=8.76]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.68it/s, epoch=3/8, avg_epoch_loss=8.58]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.64it/s, epoch=4/8, avg_epoch_loss=8.49]\n",
            "100%|██████████| 150/150 [00:57<00:00,  2.60it/s, epoch=5/8, avg_epoch_loss=8.4] \n",
            "100%|██████████| 150/150 [00:57<00:00,  2.59it/s, epoch=6/8, avg_epoch_loss=8.32]\n",
            "100%|██████████| 150/150 [00:57<00:00,  2.63it/s, epoch=7/8, avg_epoch_loss=8.27]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.65it/s, epoch=8/8, avg_epoch_loss=8.2] \n",
            "Running evaluation: 1it [00:00,  6.88it/s]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.66it/s, epoch=1/8, avg_epoch_loss=9.37]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.67it/s, epoch=2/8, avg_epoch_loss=8.71]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.66it/s, epoch=3/8, avg_epoch_loss=8.54]\n",
            "100%|██████████| 150/150 [00:57<00:00,  2.63it/s, epoch=4/8, avg_epoch_loss=8.39]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.64it/s, epoch=5/8, avg_epoch_loss=8.3] \n",
            "100%|██████████| 150/150 [00:55<00:00,  2.72it/s, epoch=6/8, avg_epoch_loss=8.2]\n",
            "100%|██████████| 150/150 [00:57<00:00,  2.63it/s, epoch=7/8, avg_epoch_loss=8.14]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.64it/s, epoch=8/8, avg_epoch_loss=8.1]\n",
            "Running evaluation: 1it [00:00,  5.96it/s]\n",
            "100%|██████████| 150/150 [01:36<00:00,  1.55it/s, epoch=1/8, avg_epoch_loss=9.35]\n",
            "100%|██████████| 150/150 [01:36<00:00,  1.55it/s, epoch=2/8, avg_epoch_loss=8.77]\n",
            "100%|██████████| 150/150 [01:34<00:00,  1.58it/s, epoch=3/8, avg_epoch_loss=8.64]\n",
            "100%|██████████| 150/150 [01:36<00:00,  1.55it/s, epoch=4/8, avg_epoch_loss=8.54]\n",
            "100%|██████████| 150/150 [01:36<00:00,  1.55it/s, epoch=5/8, avg_epoch_loss=8.42]\n",
            "100%|██████████| 150/150 [01:36<00:00,  1.55it/s, epoch=6/8, avg_epoch_loss=8.38]\n",
            "100%|██████████| 150/150 [01:37<00:00,  1.55it/s, epoch=7/8, avg_epoch_loss=8.29]\n",
            "100%|██████████| 150/150 [01:37<00:00,  1.54it/s, epoch=8/8, avg_epoch_loss=8.24]\n",
            "Running evaluation: 1it [00:00,  6.03it/s]\n",
            "100%|██████████| 150/150 [01:40<00:00,  1.50it/s, epoch=1/8, avg_epoch_loss=9.23]\n",
            "100%|██████████| 150/150 [01:35<00:00,  1.57it/s, epoch=2/8, avg_epoch_loss=8.7] \n",
            "100%|██████████| 150/150 [01:36<00:00,  1.56it/s, epoch=3/8, avg_epoch_loss=8.59]\n",
            "100%|██████████| 150/150 [01:36<00:00,  1.55it/s, epoch=4/8, avg_epoch_loss=8.49]\n",
            "100%|██████████| 150/150 [01:35<00:00,  1.57it/s, epoch=5/8, avg_epoch_loss=8.44]\n",
            "100%|██████████| 150/150 [01:34<00:00,  1.60it/s, epoch=6/8, avg_epoch_loss=8.36]\n",
            "100%|██████████| 150/150 [01:34<00:00,  1.59it/s, epoch=7/8, avg_epoch_loss=8.29]\n",
            "100%|██████████| 150/150 [01:31<00:00,  1.64it/s, epoch=8/8, avg_epoch_loss=8.19]\n",
            "Running evaluation: 1it [00:00,  5.67it/s]\n",
            "100%|██████████| 150/150 [01:05<00:00,  2.30it/s, epoch=1/8, avg_epoch_loss=9.17]\n",
            "100%|██████████| 150/150 [01:04<00:00,  2.31it/s, epoch=2/8, avg_epoch_loss=8.68]\n",
            "100%|██████████| 150/150 [01:04<00:00,  2.32it/s, epoch=3/8, avg_epoch_loss=8.49]\n",
            "100%|██████████| 150/150 [01:04<00:00,  2.33it/s, epoch=4/8, avg_epoch_loss=8.33]\n",
            "100%|██████████| 150/150 [01:05<00:00,  2.31it/s, epoch=5/8, avg_epoch_loss=8.24]\n",
            "100%|██████████| 150/150 [01:04<00:00,  2.34it/s, epoch=6/8, avg_epoch_loss=8.18]\n",
            "100%|██████████| 150/150 [01:05<00:00,  2.29it/s, epoch=7/8, avg_epoch_loss=8.12]\n",
            "100%|██████████| 150/150 [01:05<00:00,  2.30it/s, epoch=8/8, avg_epoch_loss=8.11]\n",
            "Running evaluation: 1it [00:00,  5.43it/s]\n",
            "100%|██████████| 150/150 [01:04<00:00,  2.33it/s, epoch=1/8, avg_epoch_loss=9.29]\n",
            "100%|██████████| 150/150 [01:02<00:00,  2.40it/s, epoch=2/8, avg_epoch_loss=8.65]\n",
            "100%|██████████| 150/150 [01:02<00:00,  2.38it/s, epoch=3/8, avg_epoch_loss=8.5]\n",
            "100%|██████████| 150/150 [01:03<00:00,  2.36it/s, epoch=4/8, avg_epoch_loss=8.36]\n",
            "100%|██████████| 150/150 [01:04<00:00,  2.32it/s, epoch=5/8, avg_epoch_loss=8.23]\n",
            "100%|██████████| 150/150 [01:05<00:00,  2.31it/s, epoch=6/8, avg_epoch_loss=8.16]\n",
            "100%|██████████| 150/150 [01:04<00:00,  2.32it/s, epoch=7/8, avg_epoch_loss=8.12]\n",
            "100%|██████████| 150/150 [01:03<00:00,  2.37it/s, epoch=8/8, avg_epoch_loss=8.07]\n",
            "Running evaluation: 1it [00:00,  5.88it/s]\n",
            "100%|██████████| 150/150 [01:59<00:00,  1.25it/s, epoch=1/8, avg_epoch_loss=9.33]\n",
            "100%|██████████| 150/150 [01:56<00:00,  1.29it/s, epoch=2/8, avg_epoch_loss=8.79]\n",
            "100%|██████████| 150/150 [01:56<00:00,  1.29it/s, epoch=3/8, avg_epoch_loss=8.55]\n",
            "100%|██████████| 150/150 [01:56<00:00,  1.29it/s, epoch=4/8, avg_epoch_loss=8.42]\n",
            "100%|██████████| 150/150 [01:56<00:00,  1.29it/s, epoch=5/8, avg_epoch_loss=8.35]\n",
            "100%|██████████| 150/150 [01:57<00:00,  1.28it/s, epoch=6/8, avg_epoch_loss=8.26]\n",
            "100%|██████████| 150/150 [01:55<00:00,  1.30it/s, epoch=7/8, avg_epoch_loss=8.23]\n",
            "100%|██████████| 150/150 [01:56<00:00,  1.29it/s, epoch=8/8, avg_epoch_loss=8.13]\n",
            "Running evaluation: 1it [00:00,  5.44it/s]\n",
            "100%|██████████| 150/150 [01:55<00:00,  1.30it/s, epoch=1/8, avg_epoch_loss=9.3] \n",
            "100%|██████████| 150/150 [01:54<00:00,  1.31it/s, epoch=2/8, avg_epoch_loss=8.81]\n",
            "100%|██████████| 150/150 [01:52<00:00,  1.34it/s, epoch=3/8, avg_epoch_loss=8.67]\n",
            "100%|██████████| 150/150 [01:49<00:00,  1.37it/s, epoch=4/8, avg_epoch_loss=8.49]\n",
            "100%|██████████| 150/150 [01:50<00:00,  1.36it/s, epoch=5/8, avg_epoch_loss=8.52]\n",
            "100%|██████████| 150/150 [01:49<00:00,  1.37it/s, epoch=6/8, avg_epoch_loss=8.36]\n",
            "100%|██████████| 150/150 [01:48<00:00,  1.39it/s, epoch=7/8, avg_epoch_loss=8.23]\n",
            "100%|██████████| 150/150 [01:48<00:00,  1.39it/s, epoch=8/8, avg_epoch_loss=8.2]\n",
            "Running evaluation: 1it [00:00,  6.02it/s]\n",
            "100%|██████████| 100/100 [00:38<00:00,  2.62it/s, epoch=1/12, avg_epoch_loss=9.44]\n",
            "100%|██████████| 100/100 [00:37<00:00,  2.69it/s, epoch=2/12, avg_epoch_loss=8.83]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.74it/s, epoch=3/12, avg_epoch_loss=8.61]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.73it/s, epoch=4/12, avg_epoch_loss=8.5]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.73it/s, epoch=5/12, avg_epoch_loss=8.42]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.75it/s, epoch=6/12, avg_epoch_loss=8.35]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.72it/s, epoch=7/12, avg_epoch_loss=8.3]\n",
            "100%|██████████| 100/100 [00:35<00:00,  2.80it/s, epoch=8/12, avg_epoch_loss=8.27]\n",
            "100%|██████████| 100/100 [00:35<00:00,  2.84it/s, epoch=9/12, avg_epoch_loss=8.22]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.76it/s, epoch=10/12, avg_epoch_loss=8.17]\n",
            "100%|██████████| 100/100 [00:35<00:00,  2.81it/s, epoch=11/12, avg_epoch_loss=8.16]\n",
            "100%|██████████| 100/100 [00:35<00:00,  2.79it/s, epoch=12/12, avg_epoch_loss=8.15]\n",
            "Running evaluation: 1it [00:00,  5.74it/s]\n",
            "100%|██████████| 100/100 [00:37<00:00,  2.63it/s, epoch=1/12, avg_epoch_loss=9.68]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.72it/s, epoch=2/12, avg_epoch_loss=8.91]\n",
            "100%|██████████| 100/100 [00:37<00:00,  2.70it/s, epoch=3/12, avg_epoch_loss=8.72]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.72it/s, epoch=4/12, avg_epoch_loss=8.59]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.76it/s, epoch=5/12, avg_epoch_loss=8.48]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.74it/s, epoch=6/12, avg_epoch_loss=8.4]\n",
            "100%|██████████| 100/100 [00:37<00:00,  2.68it/s, epoch=7/12, avg_epoch_loss=8.33]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.70it/s, epoch=8/12, avg_epoch_loss=8.22]\n",
            "100%|██████████| 100/100 [00:37<00:00,  2.67it/s, epoch=9/12, avg_epoch_loss=8.17]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.70it/s, epoch=10/12, avg_epoch_loss=8.11]\n",
            "100%|██████████| 100/100 [00:36<00:00,  2.73it/s, epoch=11/12, avg_epoch_loss=8.09]\n",
            "100%|██████████| 100/100 [00:35<00:00,  2.79it/s, epoch=12/12, avg_epoch_loss=8.05]\n",
            "Running evaluation: 1it [00:00,  5.62it/s]\n",
            "100%|██████████| 100/100 [01:05<00:00,  1.53it/s, epoch=1/12, avg_epoch_loss=9.49]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.62it/s, epoch=2/12, avg_epoch_loss=8.83]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.59it/s, epoch=3/12, avg_epoch_loss=8.67]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.59it/s, epoch=4/12, avg_epoch_loss=8.59]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.61it/s, epoch=5/12, avg_epoch_loss=8.56]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.62it/s, epoch=6/12, avg_epoch_loss=8.46]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.60it/s, epoch=7/12, avg_epoch_loss=8.43]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.61it/s, epoch=8/12, avg_epoch_loss=8.41]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.61it/s, epoch=9/12, avg_epoch_loss=8.33]\n",
            "100%|██████████| 100/100 [01:02<00:00,  1.61it/s, epoch=10/12, avg_epoch_loss=8.31]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.63it/s, epoch=11/12, avg_epoch_loss=8.27]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.62it/s, epoch=12/12, avg_epoch_loss=8.22]\n",
            "Running evaluation: 1it [00:00,  5.50it/s]\n",
            "100%|██████████| 100/100 [01:04<00:00,  1.54it/s, epoch=1/12, avg_epoch_loss=9.45]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.63it/s, epoch=2/12, avg_epoch_loss=8.92]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.61it/s, epoch=3/12, avg_epoch_loss=8.77]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.61it/s, epoch=4/12, avg_epoch_loss=8.62]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.62it/s, epoch=5/12, avg_epoch_loss=8.55]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.62it/s, epoch=6/12, avg_epoch_loss=8.51]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.62it/s, epoch=7/12, avg_epoch_loss=8.45]\n",
            "100%|██████████| 100/100 [01:00<00:00,  1.66it/s, epoch=8/12, avg_epoch_loss=8.39]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.62it/s, epoch=9/12, avg_epoch_loss=8.35]\n",
            "100%|██████████| 100/100 [01:00<00:00,  1.66it/s, epoch=10/12, avg_epoch_loss=8.34]\n",
            "100%|██████████| 100/100 [01:01<00:00,  1.62it/s, epoch=11/12, avg_epoch_loss=8.28]\n",
            "100%|██████████| 100/100 [01:00<00:00,  1.64it/s, epoch=12/12, avg_epoch_loss=8.24]\n",
            "Running evaluation: 1it [00:00,  5.49it/s]\n",
            "100%|██████████| 100/100 [00:43<00:00,  2.30it/s, epoch=1/12, avg_epoch_loss=9.36]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.38it/s, epoch=2/12, avg_epoch_loss=8.92]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.37it/s, epoch=3/12, avg_epoch_loss=8.78]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.43it/s, epoch=4/12, avg_epoch_loss=8.66]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.38it/s, epoch=5/12, avg_epoch_loss=8.6]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.36it/s, epoch=6/12, avg_epoch_loss=8.51]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.39it/s, epoch=7/12, avg_epoch_loss=8.47]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.36it/s, epoch=8/12, avg_epoch_loss=8.42]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.37it/s, epoch=9/12, avg_epoch_loss=8.36]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.42it/s, epoch=10/12, avg_epoch_loss=8.31]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.41it/s, epoch=11/12, avg_epoch_loss=8.27]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.41it/s, epoch=12/12, avg_epoch_loss=8.22]\n",
            "Running evaluation: 1it [00:00,  5.40it/s]\n",
            "100%|██████████| 100/100 [00:42<00:00,  2.34it/s, epoch=1/12, avg_epoch_loss=9.55]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.40it/s, epoch=2/12, avg_epoch_loss=8.83]\n",
            "100%|██████████| 100/100 [00:40<00:00,  2.48it/s, epoch=3/12, avg_epoch_loss=8.66]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.38it/s, epoch=4/12, avg_epoch_loss=8.58]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.42it/s, epoch=5/12, avg_epoch_loss=8.44]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.39it/s, epoch=6/12, avg_epoch_loss=8.39]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.43it/s, epoch=7/12, avg_epoch_loss=8.35]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.40it/s, epoch=8/12, avg_epoch_loss=8.28]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.42it/s, epoch=9/12, avg_epoch_loss=8.24]\n",
            "100%|██████████| 100/100 [00:41<00:00,  2.43it/s, epoch=10/12, avg_epoch_loss=8.19]\n",
            "100%|██████████| 100/100 [00:40<00:00,  2.45it/s, epoch=11/12, avg_epoch_loss=8.19]\n",
            "100%|██████████| 100/100 [00:40<00:00,  2.46it/s, epoch=12/12, avg_epoch_loss=8.22]\n",
            "Running evaluation: 1it [00:00,  5.26it/s]\n",
            "100%|██████████| 100/100 [01:15<00:00,  1.32it/s, epoch=1/12, avg_epoch_loss=9.52]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=2/12, avg_epoch_loss=8.94]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.38it/s, epoch=3/12, avg_epoch_loss=8.8]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=4/12, avg_epoch_loss=8.71]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=5/12, avg_epoch_loss=8.6]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=6/12, avg_epoch_loss=8.5]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.37it/s, epoch=7/12, avg_epoch_loss=8.42]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.37it/s, epoch=8/12, avg_epoch_loss=8.36]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.37it/s, epoch=9/12, avg_epoch_loss=8.4]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=10/12, avg_epoch_loss=8.26]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.36it/s, epoch=11/12, avg_epoch_loss=8.25]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=12/12, avg_epoch_loss=8.22]\n",
            "Running evaluation: 1it [00:00,  5.21it/s]\n",
            "100%|██████████| 100/100 [01:16<00:00,  1.30it/s, epoch=1/12, avg_epoch_loss=9.56]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=2/12, avg_epoch_loss=8.82]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.35it/s, epoch=3/12, avg_epoch_loss=8.62]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.37it/s, epoch=4/12, avg_epoch_loss=8.55]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.36it/s, epoch=5/12, avg_epoch_loss=8.44]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.37it/s, epoch=6/12, avg_epoch_loss=8.31]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.38it/s, epoch=7/12, avg_epoch_loss=8.25]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.37it/s, epoch=8/12, avg_epoch_loss=8.22]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.38it/s, epoch=9/12, avg_epoch_loss=8.12]\n",
            "100%|██████████| 100/100 [01:13<00:00,  1.36it/s, epoch=10/12, avg_epoch_loss=8.16]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.38it/s, epoch=11/12, avg_epoch_loss=8.08]\n",
            "100%|██████████| 100/100 [01:12<00:00,  1.38it/s, epoch=12/12, avg_epoch_loss=8.05]\n",
            "Running evaluation: 1it [00:00,  5.17it/s]\n",
            "100%|██████████| 150/150 [00:57<00:00,  2.61it/s, epoch=1/12, avg_epoch_loss=9.25]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.66it/s, epoch=2/12, avg_epoch_loss=8.68]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.69it/s, epoch=3/12, avg_epoch_loss=8.53]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.70it/s, epoch=4/12, avg_epoch_loss=8.4] \n",
            "100%|██████████| 150/150 [00:55<00:00,  2.70it/s, epoch=5/12, avg_epoch_loss=8.32]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.69it/s, epoch=6/12, avg_epoch_loss=8.25]\n",
            "100%|██████████| 150/150 [00:54<00:00,  2.73it/s, epoch=7/12, avg_epoch_loss=8.16]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.70it/s, epoch=8/12, avg_epoch_loss=8.15]\n",
            "100%|██████████| 150/150 [00:54<00:00,  2.73it/s, epoch=9/12, avg_epoch_loss=8.11]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.70it/s, epoch=10/12, avg_epoch_loss=8.09]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.67it/s, epoch=11/12, avg_epoch_loss=8.07]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.69it/s, epoch=12/12, avg_epoch_loss=8.04]\n",
            "Running evaluation: 1it [00:00,  4.83it/s]\n",
            "100%|██████████| 150/150 [00:56<00:00,  2.64it/s, epoch=1/12, avg_epoch_loss=9.45]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.71it/s, epoch=2/12, avg_epoch_loss=8.71]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.71it/s, epoch=3/12, avg_epoch_loss=8.51]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.71it/s, epoch=4/12, avg_epoch_loss=8.34]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.71it/s, epoch=5/12, avg_epoch_loss=8.22]\n",
            "100%|██████████| 150/150 [00:54<00:00,  2.73it/s, epoch=6/12, avg_epoch_loss=8.17]\n",
            "100%|██████████| 150/150 [00:54<00:00,  2.74it/s, epoch=7/12, avg_epoch_loss=8.11]\n",
            "100%|██████████| 150/150 [00:54<00:00,  2.74it/s, epoch=8/12, avg_epoch_loss=8.09]\n",
            "100%|██████████| 150/150 [00:54<00:00,  2.76it/s, epoch=9/12, avg_epoch_loss=8.07]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.72it/s, epoch=10/12, avg_epoch_loss=8.03]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.72it/s, epoch=11/12, avg_epoch_loss=8.03]\n",
            "100%|██████████| 150/150 [00:55<00:00,  2.69it/s, epoch=12/12, avg_epoch_loss=8.02]\n",
            "Running evaluation: 1it [00:00,  4.81it/s]\n",
            "100%|██████████| 150/150 [01:38<00:00,  1.52it/s, epoch=1/12, avg_epoch_loss=9.42]\n",
            "100%|██████████| 150/150 [01:35<00:00,  1.57it/s, epoch=2/12, avg_epoch_loss=8.77]\n",
            "100%|██████████| 150/150 [01:35<00:00,  1.57it/s, epoch=3/12, avg_epoch_loss=8.6] \n",
            "100%|██████████| 150/150 [01:34<00:00,  1.58it/s, epoch=4/12, avg_epoch_loss=8.48]\n",
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, epoch=5/12, avg_epoch_loss=8.45]\n",
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, epoch=6/12, avg_epoch_loss=8.31]\n",
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, epoch=7/12, avg_epoch_loss=8.28]\n",
            "100%|██████████| 150/150 [01:34<00:00,  1.59it/s, epoch=8/12, avg_epoch_loss=8.2]\n",
            "100%|██████████| 150/150 [01:34<00:00,  1.59it/s, epoch=9/12, avg_epoch_loss=8.2]\n",
            "100%|██████████| 150/150 [01:34<00:00,  1.59it/s, epoch=10/12, avg_epoch_loss=8.12]\n",
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, epoch=11/12, avg_epoch_loss=8.09]\n",
            "100%|██████████| 150/150 [01:33<00:00,  1.60it/s, epoch=12/12, avg_epoch_loss=8.13]\n",
            "Running evaluation: 1it [00:00,  4.80it/s]\n",
            "100%|██████████| 150/150 [01:35<00:00,  1.58it/s, epoch=1/12, avg_epoch_loss=9.3]\n",
            "100%|██████████| 150/150 [01:32<00:00,  1.63it/s, epoch=2/12, avg_epoch_loss=8.75]\n",
            "100%|██████████| 150/150 [01:32<00:00,  1.63it/s, epoch=3/12, avg_epoch_loss=8.61]\n",
            "100%|██████████| 150/150 [01:31<00:00,  1.65it/s, epoch=4/12, avg_epoch_loss=8.47]\n",
            "100%|██████████| 150/150 [01:31<00:00,  1.64it/s, epoch=5/12, avg_epoch_loss=8.39]\n",
            "100%|██████████| 150/150 [01:31<00:00,  1.64it/s, epoch=6/12, avg_epoch_loss=8.37]\n",
            "100%|██████████| 150/150 [01:30<00:00,  1.65it/s, epoch=7/12, avg_epoch_loss=8.25]\n",
            "100%|██████████| 150/150 [01:30<00:00,  1.66it/s, epoch=8/12, avg_epoch_loss=8.19]\n",
            "100%|██████████| 150/150 [01:30<00:00,  1.66it/s, epoch=9/12, avg_epoch_loss=8.13]\n",
            "100%|██████████| 150/150 [01:31<00:00,  1.63it/s, epoch=10/12, avg_epoch_loss=8.15]\n",
            "100%|██████████| 150/150 [01:31<00:00,  1.64it/s, epoch=11/12, avg_epoch_loss=8.07]\n",
            "100%|██████████| 150/150 [01:31<00:00,  1.64it/s, epoch=12/12, avg_epoch_loss=8.06]\n",
            "Running evaluation: 1it [00:00,  4.89it/s]\n",
            "100%|██████████| 150/150 [01:02<00:00,  2.42it/s, epoch=1/12, avg_epoch_loss=9.21]\n",
            "100%|██████████| 150/150 [01:01<00:00,  2.45it/s, epoch=2/12, avg_epoch_loss=8.75]\n",
            "100%|██████████| 150/150 [01:00<00:00,  2.46it/s, epoch=3/12, avg_epoch_loss=8.61]\n",
            "100%|██████████| 150/150 [01:01<00:00,  2.42it/s, epoch=4/12, avg_epoch_loss=8.51]\n",
            "100%|██████████| 150/150 [01:02<00:00,  2.41it/s, epoch=5/12, avg_epoch_loss=8.5]\n",
            "100%|██████████| 150/150 [01:03<00:00,  2.37it/s, epoch=6/12, avg_epoch_loss=8.38]\n",
            "100%|██████████| 150/150 [01:03<00:00,  2.37it/s, epoch=7/12, avg_epoch_loss=8.31]\n",
            "100%|██████████| 150/150 [01:03<00:00,  2.38it/s, epoch=8/12, avg_epoch_loss=8.24]\n",
            "100%|██████████| 150/150 [01:02<00:00,  2.39it/s, epoch=9/12, avg_epoch_loss=8.19]\n",
            "100%|██████████| 150/150 [01:03<00:00,  2.37it/s, epoch=10/12, avg_epoch_loss=8.13]\n",
            "100%|██████████| 150/150 [01:03<00:00,  2.36it/s, epoch=11/12, avg_epoch_loss=8.09]\n",
            "100%|██████████| 150/150 [01:03<00:00,  2.38it/s, epoch=12/12, avg_epoch_loss=8.07]\n",
            "Running evaluation: 1it [00:00,  4.00it/s]\n",
            "100%|██████████| 150/150 [01:02<00:00,  2.38it/s, epoch=1/12, avg_epoch_loss=9.27]\n",
            "100%|██████████| 150/150 [01:02<00:00,  2.39it/s, epoch=2/12, avg_epoch_loss=8.69]\n",
            "100%|██████████| 150/150 [01:03<00:00,  2.35it/s, epoch=3/12, avg_epoch_loss=8.5]\n",
            "100%|██████████| 150/150 [01:01<00:00,  2.43it/s, epoch=4/12, avg_epoch_loss=8.37]\n",
            "100%|██████████| 150/150 [01:02<00:00,  2.40it/s, epoch=5/12, avg_epoch_loss=8.26]\n",
            "100%|██████████| 150/150 [01:01<00:00,  2.44it/s, epoch=6/12, avg_epoch_loss=8.24]\n",
            "100%|██████████| 150/150 [01:01<00:00,  2.43it/s, epoch=7/12, avg_epoch_loss=8.14]\n",
            "100%|██████████| 150/150 [01:01<00:00,  2.42it/s, epoch=8/12, avg_epoch_loss=8.12]\n",
            "100%|██████████| 150/150 [01:00<00:00,  2.47it/s, epoch=9/12, avg_epoch_loss=8.05]\n",
            "100%|██████████| 150/150 [01:01<00:00,  2.45it/s, epoch=10/12, avg_epoch_loss=8.03]\n",
            "100%|██████████| 150/150 [01:01<00:00,  2.44it/s, epoch=11/12, avg_epoch_loss=8.03]\n",
            "100%|██████████| 150/150 [01:01<00:00,  2.45it/s, epoch=12/12, avg_epoch_loss=8]\n",
            "Running evaluation: 1it [00:00,  4.18it/s]\n",
            "100%|██████████| 150/150 [01:55<00:00,  1.30it/s, epoch=1/12, avg_epoch_loss=9.32]\n",
            "100%|██████████| 150/150 [01:52<00:00,  1.33it/s, epoch=2/12, avg_epoch_loss=8.82]\n",
            "100%|██████████| 150/150 [01:52<00:00,  1.34it/s, epoch=3/12, avg_epoch_loss=8.6]\n",
            "100%|██████████| 150/150 [01:52<00:00,  1.34it/s, epoch=4/12, avg_epoch_loss=8.51]\n",
            "100%|██████████| 150/150 [01:52<00:00,  1.34it/s, epoch=5/12, avg_epoch_loss=8.4]\n",
            "100%|██████████| 150/150 [01:52<00:00,  1.34it/s, epoch=6/12, avg_epoch_loss=8.36]\n",
            "100%|██████████| 150/150 [01:52<00:00,  1.33it/s, epoch=7/12, avg_epoch_loss=8.23]\n",
            "100%|██████████| 150/150 [01:51<00:00,  1.34it/s, epoch=8/12, avg_epoch_loss=8.24]\n",
            "100%|██████████| 150/150 [01:52<00:00,  1.33it/s, epoch=9/12, avg_epoch_loss=8.16]\n",
            "100%|██████████| 150/150 [01:51<00:00,  1.34it/s, epoch=10/12, avg_epoch_loss=8.1]\n",
            "100%|██████████| 150/150 [01:51<00:00,  1.34it/s, epoch=11/12, avg_epoch_loss=8.11]\n",
            "100%|██████████| 150/150 [01:52<00:00,  1.34it/s, epoch=12/12, avg_epoch_loss=8.07]\n",
            "Running evaluation: 1it [00:00,  4.39it/s]\n",
            "100%|██████████| 150/150 [01:54<00:00,  1.31it/s, epoch=1/12, avg_epoch_loss=9.31]\n",
            "100%|██████████| 150/150 [01:51<00:00,  1.34it/s, epoch=2/12, avg_epoch_loss=8.76]\n",
            "100%|██████████| 150/150 [01:51<00:00,  1.35it/s, epoch=3/12, avg_epoch_loss=8.55]\n",
            "100%|██████████| 150/150 [01:53<00:00,  1.33it/s, epoch=4/12, avg_epoch_loss=8.43]\n",
            "100%|██████████| 150/150 [01:55<00:00,  1.30it/s, epoch=5/12, avg_epoch_loss=8.35]\n",
            "100%|██████████| 150/150 [02:00<00:00,  1.25it/s, epoch=6/12, avg_epoch_loss=8.27]\n",
            "100%|██████████| 150/150 [02:01<00:00,  1.24it/s, epoch=7/12, avg_epoch_loss=8.18]\n",
            "100%|██████████| 150/150 [01:56<00:00,  1.29it/s, epoch=8/12, avg_epoch_loss=8.12]\n",
            "100%|██████████| 150/150 [01:55<00:00,  1.29it/s, epoch=9/12, avg_epoch_loss=8.12]\n",
            "100%|██████████| 150/150 [01:57<00:00,  1.27it/s, epoch=10/12, avg_epoch_loss=8.05]\n",
            "100%|██████████| 150/150 [01:57<00:00,  1.27it/s, epoch=11/12, avg_epoch_loss=8.03]\n",
            "100%|██████████| 150/150 [01:57<00:00,  1.28it/s, epoch=12/12, avg_epoch_loss=8.01]\n",
            "Running evaluation: 1it [00:00,  3.57it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    epochs  num_batches_per_epoch  num_cells  num_layers  dropout_rate  \\\n",
            "0        8                    100         40           2          0.10   \n",
            "1        8                    100         40           2          0.01   \n",
            "2        8                    100         40           4          0.10   \n",
            "3        8                    100         40           4          0.01   \n",
            "4        8                    100         64           2          0.10   \n",
            "5        8                    100         64           2          0.01   \n",
            "6        8                    100         64           4          0.10   \n",
            "7        8                    100         64           4          0.01   \n",
            "8        8                    150         40           2          0.10   \n",
            "9        8                    150         40           2          0.01   \n",
            "10       8                    150         40           4          0.10   \n",
            "11       8                    150         40           4          0.01   \n",
            "12       8                    150         64           2          0.10   \n",
            "13       8                    150         64           2          0.01   \n",
            "14       8                    150         64           4          0.10   \n",
            "15       8                    150         64           4          0.01   \n",
            "16      12                    100         40           2          0.10   \n",
            "17      12                    100         40           2          0.01   \n",
            "18      12                    100         40           4          0.10   \n",
            "19      12                    100         40           4          0.01   \n",
            "20      12                    100         64           2          0.10   \n",
            "21      12                    100         64           2          0.01   \n",
            "22      12                    100         64           4          0.10   \n",
            "23      12                    100         64           4          0.01   \n",
            "24      12                    150         40           2          0.10   \n",
            "25      12                    150         40           2          0.01   \n",
            "26      12                    150         40           4          0.10   \n",
            "27      12                    150         40           4          0.01   \n",
            "28      12                    150         64           2          0.10   \n",
            "29      12                    150         64           2          0.01   \n",
            "30      12                    150         64           4          0.10   \n",
            "31      12                    150         64           4          0.01   \n",
            "\n",
            "        mape  \n",
            "0   0.136152  \n",
            "1   0.102798  \n",
            "2   0.104653  \n",
            "3   0.097510  \n",
            "4   0.118332  \n",
            "5   0.139776  \n",
            "6   0.191124  \n",
            "7   0.148500  \n",
            "8   0.192642  \n",
            "9   0.154756  \n",
            "10  0.094935  \n",
            "11  0.105161  \n",
            "12  0.123874  \n",
            "13  0.121371  \n",
            "14  0.201440  \n",
            "15  0.220638  \n",
            "16  0.124593  \n",
            "17  0.151865  \n",
            "18  0.203822  \n",
            "19  0.212312  \n",
            "20  0.250952  \n",
            "21  0.151468  \n",
            "22  0.121653  \n",
            "23  0.079592  \n",
            "24  0.086596  \n",
            "25  0.096093  \n",
            "26  0.176338  \n",
            "27  0.130866  \n",
            "28  0.088102  \n",
            "29  0.077161  \n",
            "30  0.074408  \n",
            "31  0.136419  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuning_results"
      ],
      "metadata": {
        "id": "wvyobXqBWqPL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f23dd00c-3506-4eab-fc67-38ec0ffb7eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    epochs  num_batches_per_epoch  num_cells  num_layers  dropout_rate  \\\n",
              "0        8                    100         40           2          0.10   \n",
              "1        8                    100         40           2          0.01   \n",
              "2        8                    100         40           4          0.10   \n",
              "3        8                    100         40           4          0.01   \n",
              "4        8                    100         64           2          0.10   \n",
              "5        8                    100         64           2          0.01   \n",
              "6        8                    100         64           4          0.10   \n",
              "7        8                    100         64           4          0.01   \n",
              "8        8                    150         40           2          0.10   \n",
              "9        8                    150         40           2          0.01   \n",
              "10       8                    150         40           4          0.10   \n",
              "11       8                    150         40           4          0.01   \n",
              "12       8                    150         64           2          0.10   \n",
              "13       8                    150         64           2          0.01   \n",
              "14       8                    150         64           4          0.10   \n",
              "15       8                    150         64           4          0.01   \n",
              "16      12                    100         40           2          0.10   \n",
              "17      12                    100         40           2          0.01   \n",
              "18      12                    100         40           4          0.10   \n",
              "19      12                    100         40           4          0.01   \n",
              "20      12                    100         64           2          0.10   \n",
              "21      12                    100         64           2          0.01   \n",
              "22      12                    100         64           4          0.10   \n",
              "23      12                    100         64           4          0.01   \n",
              "24      12                    150         40           2          0.10   \n",
              "25      12                    150         40           2          0.01   \n",
              "26      12                    150         40           4          0.10   \n",
              "27      12                    150         40           4          0.01   \n",
              "28      12                    150         64           2          0.10   \n",
              "29      12                    150         64           2          0.01   \n",
              "30      12                    150         64           4          0.10   \n",
              "31      12                    150         64           4          0.01   \n",
              "\n",
              "        mape  \n",
              "0   0.136152  \n",
              "1   0.102798  \n",
              "2   0.104653  \n",
              "3   0.097510  \n",
              "4   0.118332  \n",
              "5   0.139776  \n",
              "6   0.191124  \n",
              "7   0.148500  \n",
              "8   0.192642  \n",
              "9   0.154756  \n",
              "10  0.094935  \n",
              "11  0.105161  \n",
              "12  0.123874  \n",
              "13  0.121371  \n",
              "14  0.201440  \n",
              "15  0.220638  \n",
              "16  0.124593  \n",
              "17  0.151865  \n",
              "18  0.203822  \n",
              "19  0.212312  \n",
              "20  0.250952  \n",
              "21  0.151468  \n",
              "22  0.121653  \n",
              "23  0.079592  \n",
              "24  0.086596  \n",
              "25  0.096093  \n",
              "26  0.176338  \n",
              "27  0.130866  \n",
              "28  0.088102  \n",
              "29  0.077161  \n",
              "30  0.074408  \n",
              "31  0.136419  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c0c48563-a730-43b9-af3f-c839de147222\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epochs</th>\n",
              "      <th>num_batches_per_epoch</th>\n",
              "      <th>num_cells</th>\n",
              "      <th>num_layers</th>\n",
              "      <th>dropout_rate</th>\n",
              "      <th>mape</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.136152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.102798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.104653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.097510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.118332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.139776</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.191124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.148500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.192642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.154756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.094935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.105161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.123874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.121371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.201440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>8</td>\n",
              "      <td>150</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.220638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.124593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.151865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.203822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.212312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.250952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.151468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.121653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>12</td>\n",
              "      <td>100</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.079592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>12</td>\n",
              "      <td>150</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.086596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>12</td>\n",
              "      <td>150</td>\n",
              "      <td>40</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.096093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>12</td>\n",
              "      <td>150</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.176338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>12</td>\n",
              "      <td>150</td>\n",
              "      <td>40</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.130866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>12</td>\n",
              "      <td>150</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.088102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>12</td>\n",
              "      <td>150</td>\n",
              "      <td>64</td>\n",
              "      <td>2</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.077161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>12</td>\n",
              "      <td>150</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.074408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>12</td>\n",
              "      <td>150</td>\n",
              "      <td>64</td>\n",
              "      <td>4</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.136419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c0c48563-a730-43b9-af3f-c839de147222')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c0c48563-a730-43b9-af3f-c839de147222 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c0c48563-a730-43b9-af3f-c839de147222');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-637a2ad6-b6d5-403e-b52b-bfccf822ffa5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-637a2ad6-b6d5-403e-b52b-bfccf822ffa5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-637a2ad6-b6d5-403e-b52b-bfccf822ffa5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tuning_results",
              "summary": "{\n  \"name\": \"tuning_results\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"epochs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 8,\n        \"max\": 12,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          12,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_batches_per_epoch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 25,\n        \"min\": 100,\n        \"max\": 150,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          150,\n          100\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_cells\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12,\n        \"min\": 40,\n        \"max\": 64,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          64,\n          40\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"num_layers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 2,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"dropout_rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04572004572006858,\n        \"min\": 0.01,\n        \"max\": 0.1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.01,\n          0.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mape\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04678273354601321,\n        \"min\": 0.07440837791987828,\n        \"max\": 0.2509519032069615,\n        \"num_unique_values\": 32,\n        \"samples\": [\n          0.07716139725276402,\n          0.22063807078770228\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}