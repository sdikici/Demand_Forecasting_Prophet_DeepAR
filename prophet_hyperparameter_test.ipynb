{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "7MrLveu2h5Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sercandikici/merged-dataset-electricty-weather-for-modelling\n",
        "! unzip merged-dataset-electricty-weather-for-modelling.zip"
      ],
      "metadata": {
        "id": "RPtiYDibh2Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prophet import Prophet\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yG0I1j02hzkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true))\n",
        "    return mape\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    mse = np.mean((y_true - y_pred) ** 2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return rmse\n",
        "\n",
        "def r_squared(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    mean_y_true = np.mean(y_true)\n",
        "    ss_total = np.sum((y_true - mean_y_true) ** 2)\n",
        "    ss_residual = np.sum((y_true - y_pred) ** 2)\n",
        "    r2 = 1 - (ss_residual / ss_total)\n",
        "    return r2\n"
      ],
      "metadata": {
        "id": "zWN1D-c4hkS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged = pd.read_csv(\"merged_data.csv\")\n",
        "df_merged['settlement_date'] = pd.to_datetime(df_merged['settlement_date'])\n",
        "df_merged[\"tsd\"] = np.square(df_merged[\"tsd\"])\n",
        "df_merged"
      ],
      "metadata": {
        "id": "Qt8KfRMkhkPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_from = 90*12 #train test split is from 90days\n",
        "freq = \"2H\"\n",
        "days_to_predict=7\n",
        "periods = days_to_predict*12\n",
        "mcmc_samples = 30"
      ],
      "metadata": {
        "id": "A1bRG2BqhkMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model_3 = df_merged[[\"tsd\",\"settlement_date\",\"temp\"]]\n",
        "df_model_3.columns=[\"y\",\"ds\",\"temp\"]\n",
        "df_model_3"
      ],
      "metadata": {
        "id": "l28VQi21hkD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_3 = df_model_3[:-split_from]\n",
        "test_data_3 = df_model_3[-split_from:]"
      ],
      "metadata": {
        "id": "qosLzc58hj7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHofZPmChfHo"
      },
      "outputs": [],
      "source": [
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'changepoint_prior_scale': [0.001, 0.01, 0.05, 0.1, 0.5],\n",
        "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
        "}\n",
        "\n",
        "# Generate all combinations of parameters\n",
        "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
        "mapes = []  # Store the MAPEs for each params here\n",
        "\n",
        "# Use cross validation to evaluate all parameters\n",
        "for params in all_params:\n",
        "    # Initialize Prophet model with given params\n",
        "    m = Prophet(**params,mcmc_samples=mcmc_samples)\n",
        "    m.add_country_holidays(country_name=\"UK\")\n",
        "    m.add_regressor(\"temp\", mode=\"additive\")\n",
        "\n",
        "    # Fit the model\n",
        "    m.fit(train_data_3)\n",
        "\n",
        "    # Make future dataframe\n",
        "    future = m.make_future_dataframe(periods=periods, freq=freq)\n",
        "\n",
        "    # Add regressors to future dataframe\n",
        "    train_idx = future[\"ds\"].isin(train_data_3[\"ds\"])\n",
        "    test_idx = ~train_idx\n",
        "    reg = [\"temp\"]\n",
        "    for r in reg:\n",
        "        future.loc[train_idx, r] = train_data_3[r].to_list()\n",
        "        future.loc[test_idx, r] = test_data_3.iloc[:periods][r].to_list()\n",
        "\n",
        "    # Predict and calculate MAPE\n",
        "    forecast = m.predict(future)\n",
        "    forecast_days = forecast[forecast[\"ds\"] >= test_data_3[\"ds\"].iloc[0]]\n",
        "    test_days = test_data_3[(test_data_3[\"ds\"] >= test_data_3[\"ds\"].iloc[0]) & (test_data_3[\"ds\"] <= forecast_days[\"ds\"].iloc[-1])]\n",
        "    mape = mean_absolute_percentage_error(test_days[\"y\"], forecast_days[\"yhat\"])\n",
        "    mapes.append(mape)\n",
        "\n",
        "# Combine parameters and corresponding MAPEs into a DataFrame\n",
        "tuning_results = pd.DataFrame(all_params)\n",
        "tuning_results['mape'] = mapes\n",
        "print(tuning_results)\n"
      ]
    }
  ]
}