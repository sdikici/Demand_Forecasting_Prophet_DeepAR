{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNkH2ZBGL6hZ4w5kIZ5+L3R",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdikici/Demand_Forecasting_Prophet_DeepAR/blob/main/prophet_hyperparameter_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "7MrLveu2h5Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d sercandikici/merged-dataset-electricty-weather-for-modelling\n",
        "! unzip merged-dataset-electricty-weather-for-modelling.zip"
      ],
      "metadata": {
        "id": "RPtiYDibh2Ri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prophet import Prophet\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yG0I1j02hzkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    '''Calculate and return the Mean Absolute Percentage Error (MAPE) between actual values (y_true) and predicted values (y_pred).'''\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    mape = np.mean(np.abs((y_true - y_pred) / y_true))\n",
        "    return mape"
      ],
      "metadata": {
        "id": "zWN1D-c4hkS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Read the CSV file named \"merged_data.csv\" into a DataFrame named df_merged using the pd.read_csv function from the pandas library.\n",
        "Ensure that the 'settlement_date' column is interpreted as datetime by converting it using the pd.to_datetime function.\n",
        "'''\n",
        "\n",
        "df_merged = pd.read_csv(\"merged_data.csv\")\n",
        "df_merged['settlement_date'] = pd.to_datetime(df_merged['settlement_date'])\n",
        "df_merged"
      ],
      "metadata": {
        "id": "Qt8KfRMkhkPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Define the parameter split_from to determine the point of split between training and testing data. In this case, split_from is set to 90 days multiplied by 12, assuming hourly data.\n",
        "Define the frequency of the time series data as \"2H\" (2 hours).\n",
        "Specify the number of days to predict,and calculate the periods by multiplying days_to_predict by 12.\n",
        "Set the number of MCMC samples.\n",
        "'''\n",
        "split_from = 90*12 #train test split is from 90days\n",
        "freq = \"2H\"\n",
        "days_to_predict=7\n",
        "periods = days_to_predict*12\n",
        "mcmc_samples = 50"
      ],
      "metadata": {
        "id": "A1bRG2BqhkMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Create a new DataFrame named df_model_3 containing only the columns 'tsd', 'settlement_date', and 'temp' from df_merged.\n",
        "Rename the columns of df_model_3 to 'y', 'ds', and 'temp' respectively.\n",
        "'''\n",
        "df_model_3 = df_merged[[\"tsd\",\"settlement_date\",\"temp\"]]\n",
        "df_model_3.columns=[\"y\",\"ds\",\"temp\"]\n",
        "df_model_3"
      ],
      "metadata": {
        "id": "l28VQi21hkD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Split the df_model_3 DataFrame into training and testing sets:\n",
        "- train_data_3 contains all data points from df_model_3 except for the last entries defined by split_from, representing the last 90 days' worth of data based on the assumption of hourly recordings.\n",
        "- test_data_3 consists of the last 90 days' worth of data from df_model_3, serving as the dataset for evaluating the model's performance on unseen data.\n",
        "'''\n",
        "train_data_3 = df_model_3[:-split_from]\n",
        "test_data_3 = df_model_3[-split_from:]"
      ],
      "metadata": {
        "id": "qosLzc58hj7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHofZPmChfHo"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Define a parameter grid containing different combinations of hyperparameters for tuning the Prophet model, including changepoint_prior_scale and seasonality_prior_scale.\n",
        "\n",
        "Generate all possible combinations of parameters using itertools.product and store them in all_params.\n",
        "\n",
        "Iterate over each parameter combination in all_params:\n",
        "    - Initialize a Prophet model with the current set of parameters.\n",
        "    - Add country holidays and additional regressors (e.g., temperature) to the model.\n",
        "    - Fit the model to the training data.\n",
        "    - Create a future dataframe for forecasting.\n",
        "    - Add regressors to the future dataframe.\n",
        "    - Make predictions using the model.\n",
        "    - Calculate the MAPE between the predicted and actual values for the test period.\n",
        "    - Append the MAPE to the list mapes.\n",
        "\n",
        "Combine the parameters and corresponding MAPEs into a DataFrame named tuning_results.\n",
        "\n",
        "Print the tuning_results DataFrame to display the results of hyperparameter tuning.\n",
        "'''\n",
        "\n",
        "param_grid = {\n",
        "    'changepoint_prior_scale': [0.001, 0.01, 0.05, 0.1, 0.5],\n",
        "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
        "}\n",
        "\n",
        "# Generate all combinations of parameters\n",
        "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
        "mapes = []  # Store the MAPEs for each params here\n",
        "\n",
        "# Use cross validation to evaluate all parameters\n",
        "for params in all_params:\n",
        "    # Initialize Prophet model with given params\n",
        "    m = Prophet(**params,mcmc_samples=mcmc_samples)\n",
        "    m.add_country_holidays(country_name=\"UK\")\n",
        "    m.add_regressor(\"temp\", mode=\"additive\")\n",
        "\n",
        "    # Fit the model\n",
        "    m.fit(train_data_3)\n",
        "\n",
        "    # Make future dataframe\n",
        "    future = m.make_future_dataframe(periods=periods, freq=freq)\n",
        "\n",
        "    # Add regressors to future dataframe\n",
        "    train_idx = future[\"ds\"].isin(train_data_3[\"ds\"])\n",
        "    test_idx = ~train_idx\n",
        "    reg = [\"temp\"]\n",
        "    for r in reg:\n",
        "        future.loc[train_idx, r] = train_data_3[r].to_list()\n",
        "        future.loc[test_idx, r] = test_data_3.iloc[:periods][r].to_list()\n",
        "\n",
        "    # Predict and calculate MAPE\n",
        "    forecast = m.predict(future)\n",
        "    forecast_days = forecast[forecast[\"ds\"] >= test_data_3[\"ds\"].iloc[0]]\n",
        "    test_days = test_data_3[(test_data_3[\"ds\"] >= test_data_3[\"ds\"].iloc[0]) & (test_data_3[\"ds\"] <= forecast_days[\"ds\"].iloc[-1])]\n",
        "    mape = mean_absolute_percentage_error(test_days[\"y\"], forecast_days[\"yhat\"])\n",
        "    mapes.append(mape)\n",
        "\n",
        "# Combine parameters and corresponding MAPEs into a DataFrame\n",
        "tuning_results = pd.DataFrame(all_params)\n",
        "tuning_results['mape'] = mapes\n",
        "print(tuning_results)\n"
      ]
    }
  ]
}